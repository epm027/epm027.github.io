---
title: "Midterm Review"
subtitle: "PSTAT 120B, Spring 2025, with Dr. Brian Wainwright"
footer: "PSTAT 120B Sp25; Discussion Section 5, © Ethan P. Marzban"
logo: "Images/logo.png"
format: 
  clean-revealjs:
    theme: slides.scss
    multiplex: true
    transition: fade
    slide-number: true
    incremental: true 
    chalkboard: true
    include-before: [ '<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {enableAssistiveMml: false}});</script>']
    menu:
      side: left
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
author:
  - name: Ethan P. Marzban
    affiliations: Department of Statistics and Applied Probability; UCSB <br /> <br />
institute: "May 6, 2025"
title-slide-attributes:
    data-background-image: "Images/logo.png"
    data-background-size: "35%"
    data-background-opacity: "0.5"
    data-background-position: 80% 50%
code-annotations: hover
---

::: hidden
$$
\newcommand\R{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\1}{1\!\!1}
\newcommand{\comp}[1]{#1^{\complement}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\SD}{\mathrm{SD}}
\newcommand{\vect}[1]{\vec{\boldsymbol{#1}}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Corr}{\mathrm{Corr}}
\usepackage[makeroom]{cancel}
\newcommand{\iid}{\stackrel{\mathrm{i.i.d.}}{\sim}}
\newcommand{\probto}{\stackrel{\mathrm{p}}{\longrightarrow}}
\newcommand{\distto}{\stackrel{\mathrm{d}}{\longrightarrow}}
$$
:::

```{css echo = F}
.hscroll {
  height: 100%;
  max-height: 600px;
  max-width: 2000px;
  overflow: scroll;
}

.hscroll2 {
  height: 100%;
  max-height: 300px;
  overflow: scroll;
}

.hscroll3 {
  max-width: 2rem;
  overflow: scroll;
}
```

```{r setup, echo = F}
library(tidyverse)
library(countdown)
library(fixest)
library(modelsummary) # Make sure you have >=v2.0.0
library(GGally)
library(ggokabeito)
library(reshape2)
library(pander)
library(gridExtra)
library(cowplot)
library(readxl)      # for reading in Excel files
library(plotly)
```


## {{< fa map >}} Roadmap for Today

-   Go through some slides (including some interactive problems)

-   Work through some problems together (on the worksheet; copies can be found at the front of the room)

::: {.fragment}
::: {.callout-important}
## **Disclaimer**

I have not seen the exam yet, so I do not know exactly what will or will not be on it. Just because something does or does not show up on these slides doesn't mean it is guaranteed to show up / not show up on the exam.
:::
:::


::: {.fragment}
::: {.callout-important}
## **Disclaimer**

This review is not intended to be comprehensive; I encourage you to consult the lecture notes, textbook, homework, and your own notes.
:::
:::

# Transformations {background-color="black" background-image="https://media1.giphy.com/media/v1.Y2lkPTc5MGI3NjExaGI2ajVrb2RhY2Vyamh3a2l5Nmkwd3N3YTVwdXBla2RodTR6NzU1bSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/CWx3Qijmkf4746TtGu/giphy.gif" background-size="100rem"}

## {{< fa arrow-up-right-from-square >}} Univariate Transformations
### General Framework

::: {.callout-tip}
## Goal: **Univariate Transformations**

Given a random variable _X_ ~ _f_~_X_~(_x_), we seek the distribution of _U_ := g(_X_) for some real-valued function _g_.
:::

-   Three things uniquely characterize a distribution:
    -   Its CDF
    -   Its PDF
    -   Its MGF
    
    
## {{< fa arrow-up-right-from-square >}} Univariate Transformations
### CDF Method

-   First idea: find the CDF _F_~_U_~(_u_).

-   Often a three-step procedure:
    1)   Write $F_U(u) := \Prob(U \leq u) = \Prob(g(X) \leq u)$
    2)   Manipulate the event $\{g(X) \leq u\}$ to be of the form $\{X \in B_U\}$ for some set _B_~_u_~
    3)   Use the PDF of _X_ (which is assumed to be known!) to evaluate $\Prob(B_u)$, to find the CDF _F_~_U_~(_u_) of _U_.


## {{< fa arrow-up-right-from-square >}} Univariate Transformations
### CDF Method

::: {.callout-tip}
## **Example 1**

Let _X_ ~ Exp(β) for some β > 0, and define _Y_ := _c_ _X_ for some _c_ > 0. Use the CDF method to identify the distribution of _Y_ **by name**, including any/all relevant parameter(s).
:::



## {{< fa arrow-up-right-from-square >}} Univariate Transformations
### Method of Transformations

-   If _g_ is strictly monotonic over the support of _X_, then
$$ f_U(u) = f_X[g^{-1}(u)] \cdot \left| \frac{\mathrm{d}}{\mathrm{d}u} g^{-1}(u) \right| $$

::: {.fragment}
::: {.callout-caution}
## **Caution**

This method can only be used if the following assumptions hold:

1)    The underlying transformation is [**univariate**]{.alert} (i.e. a function of only _one_ random variable)

2)    The underlying transforamtion is [**strictly monotonic**]{.alert}
:::
:::


## {{< fa arrow-up-right-from-square >}} Univariate Transformations
### Method of Transformations

::: {.callout-tip}
## **Example 1 (revisited)**

Let _X_ ~ Exp(β) for some β > 0, and define _Y_ := _c_ _X_ for some _c_ > 0. Use the Method of Transformations to identify the distribution of _Y_ **by name**, including any/all relevant parameter(s).
:::




## {{< fa arrow-up-right-from-square >}} Univariate Transformations
### Method of MGFs

-   A useful fact is that MGFs uniquely determine distributions.
    -   For example, if I tell you _X_ has MGF $M_X(t) = e^{t^2}$, then you can automatically conclude that $X \sim \mathcal{N}(0, 2)$.
    
    
-   Two useful facts about MGFs:
    -   $M_{aX + b}(t) =$
    -   For independent _X_ and _Y_, $M_{X + Y}(t) =$
    
-   In light of these, we see that the MGF method is particularly useful when our transformation involves a linear combination of independent random variables.

## {{< fa arrow-up-right-from-square >}} Univariate Transformations
### Method of MGFs

::: {.callout-tip}
## **Example 1 (revisited)**

Let _X_ ~ Exp(β) for some β > 0, and define _Y_ := _c_ _X_ for some _c_ > 0. Use the MGF Method to identify the distribution of _Y_ **by name**, including any/all relevant parameter(s).
:::


## {{< fa arrow-up-right-from-square >}} Multivariate Transformations
### Outline

-   When it comes to [**multivariate transformations**]{.alert} (i.e. transformations of _multiple_ random variables), there often is not a one-size-fits-all approach.

-   A safe bet is usually the CDF method, though the corresponding integrals may be intractable.

-   If the transformation is a linear combination of independent random variables, then the MGF method might be a good bet.

-   We also saw some examples about minima and maxima; take a look through the lecture slides for those.



## {{< fa arrow-up-right-from-square >}} Multivariate Transformations
### Example

::: {.callout-tip}
## **Example 2**

Let $X, Y \iid \mathrm{Exp}(\beta)$ for some $\beta > 0$. Using whichever method you feel is most appropriate, identify the distribution of:

::: {.nonincremental}
a)    $S := (X + Y)$
b)    $Z := \min\{X, Y\}$
:::
:::


# Inferential Statistics {background-color="black" background-image="https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExcndtbGw5NG94OTRhbHBiN3V4bmRhcTJ4a2h5eTBoMjByc3FxZmQ0biZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/9ADoZQgs0tyww/giphy.gif" background-size="70rem"}

## {{< fa vial >}} Sampling
### General Framework

:::: {.columns}

::: {.column width="50%"}
![](Images/Inference.svg)
:::

::: {.column width="50%"}
-   **Goal:** to make inferences about a population parameter.

-   To do so, we take random [**samples**]{.alert} from the population.

-   A [**statistic**]{.alert} is a function of a random sample: $T := T(X_1, \cdots, X_n)$
    -   Statistics, therefore, are random variables; their distributions are called [**sampling distributions**]{.alert}

:::

::::


## {{< fa vial >}} Sampling
### Example: Cats!

![](Images/Sampling0.svg)


## {{< fa vial >}} Sampling
### Example: Cats!

![](Images/Sampling1.svg)


## {{< fa vial >}} Sampling
### Example: Cats!

![](Images/Sampling2.svg)


## {{< fa vial >}} Sampling
### Example: Cats!

![](Images/Sampling3.svg)

## {{< fa vial >}} Sampling
### Notation

-   With this example, we can highlight an important distinction.

-   Let _Y_~_i_~ denote the weight of a randomly-selected cat. Random or deterministic?
    -   Random.
    
-   Let _y_~_i_~ denote the weight of a specific cat (e.g. Kitty). Random or deterministic?
    -   Deterministic.
    
-   Denote $\vect{Y} := \{Y_i\}_{i=1}^{n}$ to be our [**random sample**]{.alert}; let $\vect{y} := \{y_i\}_{i=1}^{n}$ be a [**realization**]{.alert} (aka an [**observed instance**]{.alert}) of our sample $\vect{Y}$.

## {{< fa vial >}} Sampling
### Normal Population

-   Two common statistics that arise frequently are the [**sample mean**]{.alert} and [**sample variance**]{.alert}, defined as
$$ \overline{X}_n := \frac{1}{n} \sum_{i=1}^{n} X_i; \qquad S_n^2 := \frac{1}{n - 1} \sum_{i=1}^{n} (X_i - \overline{X}_n)^2 $$

::: {.fragment}
::: {.callout-important}
## **Theorem**

Let $X_1, \cdots, X_n \iid \mathcal{N}(\mu, \sigma^2)$. Then:

::: {.nonincremental}
1)    $\overline{X}_n \sim \mathcal{N}\left( \mu, \ \frac{\sigma^2}{n} \right)$
2)    $\left( \frac{n - 1}{\sigma^2} \right) S_n^2 \sim \chi^2_{n - 1}$
:::

:::
:::


## {{< fa backward-fast >}} Review: The Gamma Distribution

\

```{ojs}
viewof alph = Inputs.range(
  [0.2, 10], 
  {value: 2, step: 0.1, label: "α:"}
)

viewof bet = Inputs.range(
  [0.2, 3.1], 
  {value: 1, step: 0.01, label: "β:"}
)
```

```{ojs}
jstat = require("jstat")

plt_pdf = Plot.plot({
    width: 700,
    height: 300,
    color: {
      legend: true
    },
    x: {
      label: "x",
      axis: true
    },
    y: {
      label: "f(x)",
      //axis: false,
      //domain: [0, d3.max(pdfvals.map(d => d.pdf))]  
    },
    marks: [
      Plot.ruleY([0]),
      Plot.ruleX([0]),
      Plot.line(pdfvals, {x: "x", y: "pdf", stroke : "blue", strokeWidth: 4})
    ]
  })
  
pdfvals = {
  const x = d3.range(0, 12, 0.01);
  var pdf;
  pdf = x.map(x => ({x: x, pdf: jstat.gamma.pdf(x, alph, bet)}));
  return pdf
}
```

## {{< fa backward-fast >}} Review: The $\chi^2_{\nu}$ distribution

\

```{ojs}
viewof nu = Inputs.range(
  [0.2, 10], 
  {value: 3, step: 0.1, label: "ν:"}
)

```

```{ojs}
plt_pdf2 = Plot.plot({
    width: 700,
    height: 300,
    color: {
      legend: true
    },
    x: {
      label: "x",
      axis: true
    },
    y: {
      label: "f(x)",
      //axis: false,
      //domain: [0, d3.max(pdfvals.map(d => d.pdf))]  
    },
    marks: [
      Plot.ruleY([0]),
      Plot.ruleX([0]),
      Plot.line(pdfvals2, {x: "x", y: "pdf", stroke : "blue", strokeWidth: 4})
    ]
  })
  
pdfvals2 = {
  const x = d3.range(0, 12, 0.01);
  var pdf;
  pdf = x.map(x => ({x: x, pdf: jstat.gamma.pdf(x, nu/2, 2)}));
  return pdf
}
```


## {{< fa vial >}} Sampling
### Convergence in Distribution

::: {.callout-note}
## **Definition:** Convergence in Distribution

A sequence $\{X_n\}_{n \geq 1}$ of random variables is said to [**converge in distribution**]{.alert} to another random variable $X$ if, for every point $x$ at which the CDF of $X$ is continuous,
$$ \lim_{n \to \infty} \Prob(X_n \leq x) = \Prob(X \leq x) $$
in which case we write
$$ X_n \distto X $$
:::

## {{< fa vial >}} Sampling
### Central Limit Theorem

::: {.callout-important}
## **Central Limit Theorem**

Let $X_1, \cdots, X_n$ denote an i.i.d. sample from a distribution with mean $\mu$ and finite variance $\sigma^2 < \infty$. Then
$$ \frac{\sqrt{n}(\overline{X}_n - \mu)}{\sigma} \distto \mathcal{N}(0, 1) $$
which we can sometimes write as, for sufficiently large _n_,
$$ \overline{X}_n \stackrel{\cdot}{\sim} \mathcal{N}\left( \mu , \ \frac{\sigma^2}{n} \right) \sim \mathcal{N}\left( \E[Y_i], \ \frac{\Var(Y_i)}{n} \right) $$
:::


## {{< fa sign-hanging >}} Estimation
### General Framework

-   The goal of [**estimation**]{.alert} is, as the name suggests, to use samples (specifically, sample _statistics_) to _estimate_ the value of a population parameter.

-   Three key terms:
    -   [**Estimand:**]{.alert} another word for the parameter we are trying to estimate.
    -   [**Estimator:**]{.alert} a statistic being used to estimate the estimand.
        -   Another way to think about this: a "rule" used to estimate the parameter.
    -   [**Estimate:**]{.alert} a particular _realization_ (i.e. _observed instance_) of an estimator.
    
    
## {{< fa sign-hanging >}} Estimation
### Example

::: {.callout-tip}
## **Example**

A vet wishes to estimate the true weight of all cats in the world. She takes a sample of 10 cats, and finds their average weight to be 9.12 lbs.
:::

-   The **estimand** is the true average weight of all cats in the world (which we can call µ).

-   The **estimator** is the sample mean: we are using sample means to estimate µ.

-   The **estimate** in this scenario is 9.12 lbs, as this is a particular realization of our estimator.


    
## {{< fa sign-hanging >}} Estimation
### Goodness-of-Fit

-   Given that there are potentially _many_ estimators we could use to estimate a particular estimand, it's useful to develop a metric of how well a particular estimator is performing (or, equivalently, on how to _compare_ the performance of two estimators).

::: {.fragment}
::: {.callout-note}
## **Definition**: Bias

The [**bias**]{.alert} of an estimator $\widehat{\theta}_n$ being used to estimate a parameter $\theta$ is defined to be
$$ \mathrm{Bias}(\widehat{\theta}_n) := \E[\widehat{\theta}_n] - \theta $$
The estimator is said to be [**unbiased**]{.alert} if its bias is zero; i.e. if $\E[\widehat{\theta}_n] = \theta$.
:::
:::

-   An unbiased estimator, "on average, gets it right".



## {{< fa sign-hanging >}} Estimation
### An Analogy

-   Unbiasedness, however, is often not enough. To motivate why, let's take a look at an analogy.

-   An analogy is often drawn between estimation and hitting a bullseye.
    -   The bullseye is akin to our estimand, and estimates are represented by shots fired at the target. 
    -   The estimator is, therefore, akin to the marskperson.
    
-   An unbiased estimator is analogous to a marksperson for whom the average location of shots is the bullseye.

## {{< fa sign-hanging >}} Estimation
### Two Markspersons

-   Which of the following markspersons are "better"? 

:::: {.columns}

::: {.column width="50%"}
::: {.fragment style="text-align:center"}
![](Images/mark1.svg){width="50%"}

**Marksperson 1**
:::
:::


::: {.column width="50%"}
::: {.fragment style="text-align:center"}
![](Images/mark2.svg){width="50%"}

**Marksperson 2**
:::
:::

::::



## {{< fa sign-hanging >}} Estimation
### Mean Squared-Error (MSE)

-   So, unbiasedness is not enough; we'd also like small _variance_.

-   To that end, we introduce the [**mean squared-error**]{.alert} (MSE) of an estimator:
$$ \mathrm{MSE}(\widehat{\theta}_n) := \E\left[(\widehat{\theta}_n - \theta)^2 \right] $$

::: {.fragment}
::: {.callout-important}
## **Bias-Variance Decomposition**
$$ \mathrm{MSE}(\widehat{\theta}_n) := \mathrm{Bias}^2(\widehat{\theta}_n) + \Var(\widehat{\theta}_n) $$
:::
:::

-   **Question:** should a "good" estimator have very _high_ or very _low_ MSE?


## {{< fa sign-hanging >}} Estimation
### Consistency

-   Another useful property is that of [**consistency**]{.alert}.

::: {.fragment}
::: {.callout-note}
## **Definition:** Consistency

An estimator $\widehat{\theta}_n$ for a parameter $\theta$ is said to be [**consistent**]{.alert}, notated
$$ \widehat{\theta}_n \probto \theta $$
if, for every $\varepsilon > 0$,
$$ \lim_{n \to \infty} \Prob\left( |\widehat{\theta}_n - \theta| \leq \varepsilon \right) = 1 $$
or, equivalently,
$$ \lim_{n \to \infty} \Prob\left( |\widehat{\theta}_n - \theta| > \varepsilon \right) = 0 $$
:::
:::


## {{< fa sign-hanging >}} Estimation
### Consistency

-   $|\widehat{\theta}_n - \theta|$ essentially measures the distance between $\widehat{\theta}_n$ and $\theta$.

-   The event $\{|\widehat{\theta}_n - \theta| \leq \varepsilon\}$ is, therefore, the event that "the distance between $\widehat{\theta}_n$ and $\theta$ is small"
    -   Equivalently: the event that "$\widehat{\theta}_n$ is very close to $\theta$"
    
-   The definition of consistency asserts that this probability goes to one as the sample size increases.
    -   That is, as the sample size increases, we become more and more certain that $\widehat{\theta}_n$ will be very close to $\theta$.
    
    
## {{< fa sign-hanging >}} Estimation
### Consistency

::: {.callout-important}
## **Theorem**
Suppose $\widehat{\theta}_n$ is an unbiased estimator for $\theta$. If $\Var(\widehat{\theta}_n) \to 0$ as $n \to \infty$, then $\widehat{\theta}_n$ is a consistent estimator for $\theta$.
:::

::: {.fragment}
::: {.callout-caution}
## **Caution**

We can only apply this theorem if our estimator is unbiased!!!
:::
:::


::: {.fragment}
::: {.callout-important}
## **Corollary:** Weak Law of Large Numbers (WLLN)
If $Y_1, \cdots, Y_n$ are i.i.d. from a distribution with mean $\mu$ and finite variance $\sigma^2 < \infty$, then 
$$ \left( \frac{1}{n} \sum_{i=1}^{n} Y_i \right) \probto \E[Y_i] =: \mu $$
:::
:::


## {{< fa sign-hanging >}} Estimation
### Consistency

-   Take a look at the Week 5 lecture slides (specifically, Theorem 9.2) for more properties on consistency.

-   There is one additional theorem I'd like to highlight (sometimes called the [**Continuous Mapping Theorem**]{.alert}, or CMT):

::: {.fragment}
::: {.callout-important}
## **Continuous Mapping Theorem (CMT)**:
If $\widehat{\theta}_n$ is a consistent estimator for $\theta$, then $g(\widehat{\theta}_n)$ is a consistent estimator for $\theta$ provided that the function $g$ is continuous.
:::
:::


::: {.fragment}
::: {.callout-tip}
## **Example 3**

If $X_1, \cdots, X_n$ denotes an i.i.d. sample from a population with mean $\mu$ and finite variance $\sigma^2$, propose a consistent estimator for $\mu^2$ and show that your estimator is consistent.
:::
:::


## {{< fa sign-hanging >}} Estimation
### Consistency vs. Unbiasedness

-   A natural question is: how are consistency and unbiasedness related?

-   **Question:** are all consistent estimators unbiased?

-   **Question:** are all unbiased estimators consistent?