---
title: "Bayesian Techniques"
subtitle: "A Very Brief Introduction"
institute: "DS Collab, Winter 2024"
author: "Ethan Marzban"
footer: "UCSB: Department of Statistics and Applied Probability"
logo: "pstat_logo.svg"
format: 
  revealjs:
    theme: [moon, Styles/slides.scss]
    multiplex: true
    transition: fade
    slide-number: true
    incremental: true 
    chalkboard: true
    html-math-method: mathjax
    template-partials:
        - Styles/title-slide.html
editor: visual
execute:
  freeze: auto
title-slide-attributes:
    data-background-image: "dsc.png"
    data-background-size: contain
    data-background-opacity: "0.5"
    data-background-position: left
---

::: hidden
$$
\newcommand\R{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\1}{1\!\!1}
\newcommand{\comp}[1]{#1^{\complement}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\SD}{\mathrm{SD}}
\newcommand{\vect}[1]{\vec{\boldsymbol{#1}}}
\newcommand{\Cov}{\mathrm{Cov}}
\usepackage[makeroom]{cancel}
\newcommand{\iid}{\stackrel{\mathrm{i.i.d.}}{\sim}}
\newcommand{\Lik}{\mathcal{L}}
\DeclareMathOperator*{\argmax}{\mathrm{arg max}}
$$
:::

## Gameplan

1)  Monte Carlo simulation methods

2)  Intro to Bayesian Framework

3)  MCMC

-   **Very** brief overview; endless possibilities!

    -   PSTAT 115

-   A few prerequisites:

    -   PSTAT 120A (common distributions, random variables, probability spaces)

    -   PSTAT 120B (likelihood-based inference, confidence intervals)

# Simulation

## Leadup

-   Example Experiment: $X, Y \iid \mathrm{Unif}\{1, \cdots, 100\}$, and suppose we want to compute $\Prob(X \leq Y)$.

-   Let's do this on the board. (Final answer: 101/200)

-   We could, however, compute this using a [**simulation**]{style="color:#fa8b2f"}:

```{css echo=FALSE}
.big-code{
  font-size: 130%
}
```

::: fragment
::: big-code
```{r, echo = T}
set.seed(27)
B <- 1000

x <- sample(1:100, B, replace = T)
y <- sample(1:100, B, replace = T)
sum(x <= y) / B
```
:::
:::

## Leadup

-   Might not seem all that interesting.

-   But, suppose instead $X, Y, Z \iid \mathrm{Unif}\{1, \cdots, 100\}$, and suppose we want to compute $\Prob(X \leq Y \leq Z)$.

-   Computing this by hand becomes a bit more challenging.

-   Updating our simulation, though, is easy:

::: fragment
::: big-code
```{r, echo = T}
set.seed(27)
B <- 1000

x <- sample(1:100, B, replace = T)
y <- sample(1:100, B, replace = T)
z <- sample(1:100, B, replace = T)
sum((x <= y) & (y <= z)) / B
```
:::
:::

## Monte Carlo Simulation

::: callout-important
## Theorem 1: Monte Carlo, version 1

Let $A$ be an event with probability of occurrence $\Prob(A)$. Let $Y_n$ be defined as the proportion of times the event $A$ occurs in $n$ repetitions of the underlying experiment: then $Y_n$ converges to $\Prob(A)$ in probability: $$ Y_n \stackrel{p}{\longrightarrow} \Prob(A) $$
:::

-   Colloquially: proportion of times $A$ happens in $n$ repetitions is a good approximation for $\Prob(A)$, provided $n$ is large.

-   Proof is simple; I'll leave it in an appendix.

    -   Uses the [**Weak Law of Large Numbers**]{style="color:#fa8b2f"} (WLLN)

## Monte Carlo Integration

-   Some probabilities can be written as integrals.

-   Hence, Monte Carlo Simulation can help approximate integrals.

-   E.g. say we want to compute $$ I_1 := \frac{1}{\sqrt{2\pi}} \int_{0}^{1} e^{-x^2 / 2} \ \mathrm{d}x $$

-   If $X \sim \mathcal{N}(0, 1)$, then $I_1 = \Prob(0 \leq X \leq 1)$.

-   So, simulate a bunch of $\mathcal{N}(0, 1)$ draws and compute the proportion that are between 0 and 1.

## Monte Carlo Integration

-   Simulation:

::: fragment
::: big-code
```{r}
#| echo: TRUE
library(tidyverse)
set.seed(123)

X <- rnorm(5000)

ifelse((X >= 0) & (X <= 1), 1, 0) %>% 
  mean()
```
:::
:::

-   True Answer:

::: fragment
::: big-code
```{r}
#| echo: TRUE
integrate(dnorm, 0, 1)
```
:::
:::

## Monte Carlo Integration

::: callout-important
## Monte Carlo, version 2

Consider evaluating the integral $$ I(f) := \int_{0}^{1} f(x) \ \mathrm{d}x $$ Let $X_1, \cdots, X_n$ denote an i.i.d. sample from the $\mathrm{Unif}[0, 1]$ distribution. Then, $$ \widehat{I}(f) := \frac{1}{n} \sum_{i=1}^{n} f(X_i)  \stackrel{p}{\longrightarrow} I(f) $$
:::

## Monte Carlo Integration

-   General procedure to approximate $I(f) := \int_{a}^{b} f(x) \ \mathrm{d}x$:

    1)  Generate $X_1, \cdots, X_n \iid \mathrm{Unif}[0, 1]$

    2)  Evaluate $\widehat{I}(f) := n^{-1} \sum_{i=1}^{n} f(X_i)$

-   Example:

::: fragment
::: big-code
```{r}
#| echo: TRUE
set.seed(123)
B <- 5000
X <- runif(B)
(1/B) * (1/sqrt(2*pi)) * sum(exp(-X^2 / 2))
```
:::
:::

-   True Answer: `r integrate(dnorm, 0, 1)[[1]]`

## Moral

-   We can use *sampling* to help us compute probabilistic quantities.

# Intro to the Bayesian Framework

## Philosophy

-   For an event $A$, what does $\Prob(A)$ represent?

    -   *Beliefs*, on the event $A$.

-   Typical approach (like in 120A): [**Long-Run Frequency**]{style="color:#fa8b2f"} approach, which *defines* $\Prob(A)$ to be $$ \lim_{n \to \infty} \left( \frac{\text{\# times $A$ occurs in $n$ repetitions}}{n} \right)$$

    -   Based on the notion of *infinite repetitions* and *frequencies*.

    -   Kind of nonsensical!

## Philosophy

-   Example (due to [this](https://www.bayesrulesbook.com/chapter-1) source): in an upcoming election, a pollster claims that candidate $A$ has a $0.9$ chance of winning.

    -   Seems like a reasonable enough statement.

    -   But, from a true frequentist perspective, *this cannot be!*

        -   Infinite repetitions are impossible

    -   Rather, $\Prob(\text{$A$ wins}) = 0.9$ is a statement about *prior beliefs*, beliefs we hold prior to starting our experiment.

-   So, idea: modify our framework to allow to explicit incorporation of [**prior beliefs**]{style="color:#fa8b2f"}, which in turn will allow us to explicitly *update* our beliefs in the presence of new information.

## Bayesian Ingredients

-   3 main steps in Bayesian analysis (according to Dr. Andrew Gelman):

    1)  Set up a full probability model

    2)  Condition on observed data

    3)  Evaluate model fit, and adjust/repeat as necessary

-   Before diving in too deep, let's recap the [**frequentist**]{style="color:#fa8b2f"} way of thinking; specifically, let's review [**likelihood-based methods**]{style="color:#fa8b2f"}

## Recap of Likelihood-Based Methods

-   Consider frequentist treatment: $X_1, \cdots, X_n \iid p(x; \theta)$

    -   Notation means "draw from some known distribution with density/mass function $p(\cdot)$ and parameter(s) $\theta$."

-   [**Likelihood**]{style="color:#fa8b2f"}: given observations $X_1 = x_1, \ \cdots, X_n = x_n$, how likely are we to observe a value $\theta_0$ of $\theta$?

    -   Mathematically: joint density \begin{align*}
          \Lik_{\vect{x}}(\theta_0)    &   = p_{X_1, \cdots, X_n}(x_1, \cdots, x_n ; \theta_0)   \\
        & = \prod_{i=1}^{n} p(x_i; \theta_0)
        \end{align*}

## Quick Example

-   $X_1, \cdots, X_n \iid \mathcal{N}(\mu, 1)$.\

-   $\begin{aligned}[t]  \Lik_{\vect{x}}(\mu) & = f_{X_1, \cdots, X_n}(x_1, \cdots, x_n ; \mu) \\ & = \prod_{i=1}^{n} \left[ \frac{1}{\sqrt{2\pi}} \exp\left\{ - \frac{1}{2} (x_i - \mu)^2 \right\} \\ \right] \\ & = \frac{1}{\sqrt{2\pi}} \exp\left\{ -\frac{1}{2} \sum_{i=1}^{n} (x_i - \mu)^2 \right\} \end{aligned}$

## Transition to Bayesian

-   Key point: $\theta$ is unknown, but assumed to be deterministic.

    -   120B seeks to (among other things) develop [**estimators**]{style="color:#fa8b2f"} $\widehat{\theta}_n$ of $\theta$, that satisfy certain properties (e.g. unbiasedness, consistency, UMVUE, etc.)

-   Bayesian framework, instead, allows for incorporation of prior information by treating $\theta$ as *random*, with some [**prior distribution**]{style="color:#fa8b2f"} $\pi(\theta)$.

    -   Remember: we're trying to allow for a more explicit incorporation of *prior beliefs*!

## Transition to Bayesian

-   Not all that removed from reality!

-   E.g.: consider counting the number $N$ of diseased trees in a forest.

    -   Assuming a fixed rate $\lambda$ of diseased trees per square foot, $N \sim \mathrm{Pois}(\lambda)$.

    -   But, in reality, rate of diseased trees may vary. Better to instead let the rate $\Lambda$ vary according to a distribution (e.g. Exponential, etc.)

# Interlude: Distributions

## Gamma Distribution

-   **Notation:** $X \sim \mathrm{Gamma}(\alpha, \beta)$

-   **PDF**: $f_X(x) = \frac{1}{\Gamma(\alpha) \beta^\alpha} \cdot x^{\alpha - 1} \cdot e^{-x/\beta} \cdot \1_{\{x \geq 0\}}$

    -   $\Gamma(r) := \int_{-\infty}^{\infty} t^{r - 1} e^{-t} \ \mathrm{d}t$ if $r > 0$

-   **Expectation and Variance:** $\E[X] = \alpha \beta; \quad \Var(X) = \alpha \beta^2$

-   **MGF:** $M_X(t) = \begin{cases} (1 - \beta t)^{-\alpha} & \text{if } t < 1/\beta \\ \infty & \text{otherwise} \\ \end{cases}$

-   **CDF:** No simple closed-form expression in general.

## Gamma Distribution

```{ojs}
viewof alpha_2 = Inputs.range(
  [0.1, 5], 
  {value: 1.5, step: 0.1, label: "alpha = "}
)

viewof beta_2 = Inputs.range(
  [0.1, 5], 
  {value: 0.5, step: 0.1, label: "beta = "}
)
```

```{ojs}

margin = ({top: 20, right: 30, bottom: 30, left: 40})

height = 400

x_values_2 = d3.scaleLinear()
    .domain(d3.extent(data_2, d => d.x))
    .range([margin.left, width - margin.right])

y_values_2 = d3.scaleLinear()
    .domain([Math.min(d3.min(data_2, d => d.y),0), Math.max(1,d3.max(data_2, d => d.y))]).nice()
    .range([height - margin.bottom, margin.top])
    
line_2 = d3.line()
    .x(d => x_values_2(d.x))
    .y(d => y_values_2(d.y))

xAxis_2 = g => g
  .attr("transform", `translate(0,${height - margin.bottom})`)
  .call(d3.axisBottom(x_values_2)
      .ticks(width / 80)
      .tickSizeOuter(0))

yAxis_2 = g => g
  .attr("transform", `translate(${margin.left},0)`)
  .call(d3.axisLeft(y_values_2)
      .tickValues(d3.scaleLinear().domain(y_values_2.domain()).ticks()))

mathfn = require('https://bundle.run/mathfn@1.1.0')

abs_x=6

function gamma_pdf (input_value, alpha, beta) {
  if(input_value < 0) {
    return 0
  } else {
    let left_const = 1/(mathfn.gamma(beta_2) * beta_2**alpha_2)
    let mid_var = input_value**(alpha_2 - 1)
    let right_var = Math.exp(-input_value/beta_2)
    return left_const * mid_var * right_var
  }
}

data_2 = {
  let values = [];
  for (let x = -0.5; x < abs_x; x=x+0.01) values.push({"x":x,"y":gamma_pdf(x, alpha_2, beta_2)});
  return values;
}

d3 = require("https://d3js.org/d3.v5.min.js")

chart_2 = {
  const svg = d3.select(DOM.svg(width, height));

  svg.append("g")
      .call(xAxis_2);

  svg.append("g")
      .call(yAxis_2);
  
  svg.append("path")
      .datum(data_2)
      .attr("fill", "none")
      .attr("stroke", "#fa8b2f")
      .attr("stroke-width", 5)
      .attr("stroke-linejoin", "round")
      .attr("stroke-linecap", "round")
      .attr("d", line_2);
  
  return svg.node();
}


```

::: {style="font-size:18px; text-align:right"}
*Credit to https://observablehq.com/@dswalter/normal-distribution for the base of the original applet code*
:::

## Beta Distribution

-   **Notation:** $X \sim \mathrm{Beta}(\alpha, \beta)$

-   **PDF**: $f_X(x) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) \Gamma(\beta)} \cdot x^{\alpha - 1} \cdot (1 - x)^{\beta - 1} \cdot \1_{\{0 \leq x \leq 1\}}$

-   **Expectation and Variance:** $\E[X] = \frac{\alpha}{\alpha + \beta}; \quad \Var(X) = \frac{\alpha \beta}{(\alpha + \beta)^2 (\alpha + \beta + 1)}$

-   **MGF:** No simple closed-form in general.

-   **CDF:** No simple closed-form in general.

## Beta Distribution

```{ojs}
viewof alpha_3 = Inputs.range(
  [0, 5], 
  {value: 2, step: 0.1, label: "alpha = "}
)

viewof beta_3 = Inputs.range(
  [0, 5], 
  {value: 3, step: 0.1, label: "beta = "}
)
```

```{ojs}

width = 1000

x_values_5 = d3.scaleLinear()
    .domain(d3.extent(data_5, d => d.x))
    .range([margin.left, width - margin.right])

y_values_5 = d3.scaleLinear()
    .domain([Math.min(d3.min(data_5, d => d.y),0), Math.max(1,d3.max(data_5, d => d.y))]).nice()
    .range([height - margin.bottom, margin.top])
    
line_5 = d3.line()
    .x(d => x_values_5(d.x))
    .y(d => y_values_5(d.y))

xAxis_5 = g => g
  .attr("transform", `translate(0,${height - margin.bottom})`)
  .call(d3.axisBottom(x_values_5)
      .ticks(width / 80)
      .tickSizeOuter(0))

yAxis_5 = g => g
  .attr("transform", `translate(${margin.left},0)`)
  .call(d3.axisLeft(y_values_5)
      .tickValues(d3.scaleLinear().domain(y_values_5.domain()).ticks()))

function beta_pdf (input_value, alpha, beta) {
  if(input_value < 0) {
    return 0
  } else if(input_value > 1) {
    return 0
  } else {
    let const1 = mathfn.beta(alpha, beta)
    let var1 = input_value**(alpha - 1)
    let var2 = (1 - input_value)**(beta - 1)
    return (1/const1) * var1 * var2
  }
}

data_5 = {
  let values = [];
  for (let x = 0; x < 1; x=x+0.01) values.push({"x":x,"y":beta_pdf(x, alpha_3, beta_3)});
  return values;
}

chart_5 = {
  const svg = d3.select(DOM.svg(width, height));

  svg.append("g")
      .call(xAxis_5);

  svg.append("g")
      .call(yAxis_5);
  
  svg.append("path")
      .datum(data_5)
      .attr("fill", "none")
      .attr("stroke", "#fa8b2f")
      .attr("stroke-width", 4)
      .attr("stroke-linejoin", "round")
      .attr("stroke-linecap", "round")
      .attr("d", line_5);
  
  return svg.node();
}
```

::: {style="font-size:18px; text-align:right"}
*Credit to https://observablehq.com/@dswalter/normal-distribution for the base of the original applet code*
:::

## Densities

-   Densities are of the form $f(x; \theta) = c(\theta) \cdot k(x; \theta)$ where *c* is a constant independent of $x$ (but potentially involving parameters).

-   Key point: *c* is a *normalizing constant* (i.e. a term that ensures the density integrates to 1), and is thus uniquely determined by $k(x; \theta)$

-   In other words: [**variable part**]{style="color:#fa8b2f"} $k(x; \theta)$ of the density is enough to determine distribution.

## Example

-   For instance, say $X \sim f(x; \mu) \propto e^{-(x - \mu)^2}$.

    -   Already know that $X \sim \mathcal{N}(\mu, 1/2)$, since $$k(x; \mu) = e^{-\frac{1}{2(1/2)}(x - \mu)^2}$$ which is the variable portion (kernel) of the $\mathcal{N}(\mu, 1/2)$ distribution.

    -   Key point: don't need to know value of normalizing constant!

-   Second Example: $Y \sim f(y) \propto y\sqrt{1 - y} \cdot \1_{\{x \in [0, 1]\}}$. What distribution does $Y$ follow?

# Bayesian Modeling

## Introduction

-   [**Model**]{style="color:#fa8b2f"} (aka [**Sampling Distribution**]{style="color:#fa8b2f"}): $p(y \mid \theta)$

    -   $y$ is data; $\theta$ is the parameter

    -   This is just the familiar likelihood

-   [**Prior**]{style="color:#fa8b2f"}: $\pi(\theta)$, a distributional assertion on $\theta$

-   [**Posterior**]{style="color:#fa8b2f"}: $p(\theta \mid y)$

    -   Beliefs on $\theta$, updated to reflect data $y$.

## Introduction {style="font-size:33px"}

-   [**Bayes' Rule**]{style="color:#fa8b2f"}: $\displaystyle p(\theta \mid y) = \frac{p(y \mid \theta) \cdot \pi(\theta)}{p(y)}$

-   Note: in $\pi(\theta \mid y)$, the variable is $\theta$. Hence, $p(y)$ is part of the normalizing constant and is somewhat obsolete in identifying the distribution of $(\theta \mid y)$.

    -   Recall our discussion on the variable part of a density, from a few slides ago.

-   Hence, in Bayesian statistics, we often write $$ p(\theta \mid y) \propto p(y \mid \theta) \cdot \pi(\theta) $$ i.e. $$ \text{posterior} \propto \text{likelihood} \cdot \text{prior} $$

## Example

::: callout-tip
## Example 1

Suppose we toss a coin $10$ times. Let $X$ denote the number of heads that we observe; assume that the probability of heads on any given trial is $\Theta$.\

In the absence of any information, we may set our prior on $\theta$ to be centered at $1/2$; for now, take $\Theta \sim \mathrm{Beta}(2, 2)$.\

Assuming we observe 9 heads in our 10 tosses, find the posterior distribution $(\Theta \mid X = 8)$.
:::

## Example

-   Likelihood: $p(x \mid \theta) = \binom{10}{x} \theta^x (1 - \theta)^{10 - x}$.

-   Prior: $\pi(\theta) = 6 \theta(1 - \theta) \1_{\{0 \leq \theta \leq 1\}}$

-   Posterior: let's do it on the board.

## Result {style="font-size:33px"}

-   In general: \begin{align*}
    (X \mid \Theta = \theta) & \sim \mathrm{Bin}(n, \theta) \\ \Theta & \sim \mathrm{Beta}(r, s) \\ \implies (\Theta \mid X = x) & \sim \mathrm{Beta}(x + r \ , \ n - x + s)
    \end{align*}

-   Notice that the prior and posterior belong to the same distributional family (i.e. Beta).

-   This is an example of what is known as [**conjugacy**]{style="color:#fa8b2f"}.

    -   Specifically, in this example we showed that the Beta distribution is a conjugate prior for a Binomial likelihood (sometimes stated as "the Beta and Binomial distributions are in conjugacy").

## Common Conjugate Pairs

\

| Likelihood |     Conjugate Prior      |
|:----------:|:------------------------:|
|  Binomial  |           Beta           |
|  Poisson   |          Gamma           |
|   Normal   |      Normal (mean)       |
|   Normal   | Inverse Gamma (variance) |

## Point Estimators

-   $(\Theta \mid X = x)$ is a random variable. How to get a point estimator of $\Theta$?

-   Answer: many different possiblities, corresponding to different summary statistics.

    -   [**Posterior Mean**]{style="color:#fa8b2f"}: $\widehat{\theta}_{\mathrm{post}} := \E[\Theta \mid X]$

    -   [**Posterior Median**]{style="color:#fa8b2f"}: $\widehat{\theta}_{\mathrm{post med.}} := \mathrm{median}\{\Theta \mid X\}$

    -   [**Maximum *a posteriori*  Estimator**]{style="color:#fa8b2f"} (MAP): $\widehat{\theta}_{\mathrm{MAP}} := \argmax\limits_{\theta}\{p(\theta \mid X)\}$ (posterior mode)

## Confidence Intervals

-   Frequentist CI: $[l(Y) \ , \ u(Y)]$ such that $$ \Prob_{\theta}(l(Y) \leq Y \leq u(Y)) = 1 - \alpha $$

    -   Key point: *endpoints* are random.

-   Expect this interval to cover the "true" value of $\theta$ 95% of the time

    -   *Before* data is observed

## Confidence Intervals

```{r dev = "png", dev.args=list(bg="transparent"), fig.height=6}
source("CI_example.R")
p1
```

## Credible Intervals

::: callout-note
## Definition: Posterior Credible Intervals

A $(1 - \alpha) \times 100\%$ [**posterior credible interval**]{style="color:#fa8b2f"} is an interval $[l(y) \ , \ u(y)]$ such that $$ \Prob(\theta \in [l(y) \ , \ u(y)] \mid Y = y) = 1 - \alpha $$
:::

-   Crucially, posterior credible intervals are *not* unique.

## HPD Intervals

::: callout-note
## Definition: Highest Posterior Density Interval

A $(1 - \alpha) \times 100\%$ [**HPD interval**]{style="color:#fa8b2f"} (Highest Posterior Density interval) is an interval $A \subseteq \R$ such that:

::: nonincremental
1)  $\Prob(\theta \in A \mid Y = y) = 1 - \alpha$ (i.e. $A$ is a $(1 - \alpha) \times 100\%$ credible interval)

2)  $p(\theta_a \mid y) > p(\theta_b \mid y)$ for any $\theta_a \in A$ and $\theta_b \notin A$ (i.e. the posterior density over $A$ is higher than over any other region).
:::
:::

-   One can show that an HPD region is the *smallest* region with probability $(1 - \alpha)$

## HPD Intervals

::: callout-important
## Theorem

Let $f(x)$ be a unimodal density function, and let $I := [a, b]$ (with $-\infty < a < b < \infty$) be an interval satisfying $\int_{a}^{b} f(x) \ \mathrm{d}x = 1 - \alpha$. If:

::: nonincremental
1)  $f(a) = f(b) \neq 0$, and
2)  $I$ contains the mode of $f(x)$,
:::

then $I$ is the shortest interval such that $\int_{a}^{b} f(x) \ \mathrm{d}x = 1 - \alpha$
:::

-   Moral: for unimodal posteriors, can construct an HPD by examining intervals containing the mode.

## 70% Credible Interval

```{r dev = "png", dev.args=list(bg="transparent")}
data.frame(x = 0:1) %>%
  ggplot(aes(x = x)) + 
  stat_function(fun = dbeta, args = list(2, 4),
                geom = "area",
                xlim = c(
                  qbeta(0.15, 2, 4), 
                  qbeta(0.85, 2, 4)
                ),
                fill = "#a4caebA0",
                size = 1) +
  stat_function(fun = dbeta, args = list(2, 4),
                col = "#fa8b2f",
                size = 1) +
  theme_minimal(base_size = 14) +
  xlab("x") + ylab("y") +
  theme(
    axis.text = element_text(colour = "white"),
    axis.title = element_text(colour = "white", size = 24),
    title = element_text(color = "white", size = 28),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.text = element_text(colour = "white",
                               size = 18),
    legend.title = element_text(size = 24)
  )
```

## 70% Credible Interval

```{r dev = "png", dev.args=list(bg="transparent")}
data.frame(x = 0:1) %>%
  ggplot(aes(x = x)) + 
  stat_function(fun = dbeta, args = list(2, 4),
                geom = "area",
                xlim = c(
                  qbeta(0.3, 2, 4), 
                  qbeta(1, 2, 4)
                ),
                fill = "#a4caebA0",
                size = 1) +
  stat_function(fun = dbeta, args = list(2, 4),
                col = "#fa8b2f",
                size = 1) +
  theme_minimal(base_size = 14) +
  xlab("x") + ylab("y") +
  theme(
    axis.text = element_text(colour = "white"),
    axis.title = element_text(colour = "white", size = 24),
    title = element_text(color = "white", size = 28),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.text = element_text(colour = "white",
                               size = 18),
    legend.title = element_text(size = 24)
  )
```

## 70% HPD Interval

::: big-code
```{r}
#| echo: TRUE
library(HDInterval)

hdi(qbeta, 
    credMass = 0.7, 
    shape1 = 2, 
    shape2 = 4
)
```
:::

## 70% HPD Interval

```{r dev = "png", dev.args=list(bg="transparent")}

hpd_int <- hdi(qbeta, 
    credMass = 0.7, 
    shape1 = 2, 
    shape2 = 4
)
data.frame(x = 0:1) %>%
  ggplot(aes(x = x)) + 
  stat_function(fun = dbeta, args = list(2, 4),
                geom = "area",
                xlim = c(
                  as.numeric(hpd_int[1]), 
                  as.numeric(hpd_int[2])
                ),
                fill = "#a4caebA0",
                size = 1) +
  stat_function(fun = dbeta, args = list(2, 4),
                col = "#fa8b2f",
                size = 1) +
  theme_minimal(base_size = 14) +
  xlab("x") + ylab("y") +
  theme(
    axis.text = element_text(colour = "white"),
    axis.title = element_text(colour = "white", size = 24),
    title = element_text(color = "white", size = 28),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.text = element_text(colour = "white",
                               size = 18),
    legend.title = element_text(size = 24)
  )
```

## Two-Parameter Models

-   E.g. $(Y \mid \mu , \sigma^2) \sim \mathcal{N}(\mu, \sigma^2)$.

-   Can show $\mu \sim \mathcal{N}(\cdot, \cdot)$ is conjugate prior for $\mu$, assuming $\sigma^2$ is known.

-   Can show $\sigma^2 \sim \mathrm{InvGamm}(\cdot, \cdot)$ is conjugate prior for $\sigma^2$, assuming $\mu = 0$.

-   Instead, could specify a *joint* prior $\pi(\mu, \sigma^2)$.

-   Computations analogous to one-parameter case.

# Choosing a Prior

## Choice of Prior

-   How to pick an appropriate prior?

-   Several different schools of thought.

-   First idea: conjugacy.

    -   Pros: easy, and computationally tractable

    -   Cons: potentially too restrictive

-   Second idea: [**noninformative priors**]{style="color:#fa8b2f"}. Loosely speaking: set prior $\pi(\theta) \propto \mathrm{const}$ on the appropriate support.

    -   Pros: allows for more flexibility

    -   Cons: doesn't always lead to a propr posterior; also, might be better to inject information by way of [**domain knowledge**]{style="color:#fa8b2f"}.

## Example of an Uninformative Prior

-   $X \sim \mathcal{N}(0, \sigma^2)$

-   $\pi(\sigma^2) \propto 1/(\sigma^2)$ on $(0, \infty)$.

    -   Not a proper density; integrates to $\infty!$

-   $\begin{aligned}[t]  p(\sigma^2 \mid X = x) & \propto p(X \mid \sigma^2) \cdot \pi(\sigma^2) \\ & \propto \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left\{ - \frac{1}{2 \sigma^2} x^2 \right\} \cdot \frac{1}{\sigma^2} \\ & \propto \frac{1}{(\sigma^2)^{3/2}} \cdot \exp\left\{ - \frac{x^2}{2(\sigma^2)} \right\} \\ & \sim \mathrm{InvGamma}(4, x) \end{aligned}$

# Sampling from the Posterior

## Leadup

-   At the start of this lesson, we saw the importance and power of Monte Carlo simulation.

-   Key idea: if we can draw from a posterior, we can avoid a lot of pesky math.

-   Sampling from posterior: easy enough for "famous" distributions (e.g. normal, beta, uniform, etc.)

-   But, for more complicated posteriors (which arise frequently in real-life), isn't always so simple!

## Sampling from the Posterior

-   Goal: generate sample $\theta^{(s)} \sim p(\theta \mid x_1, \cdots, x_n)$.

-   Several techniques available:

    -   [**Grid Approximation**]{style="color:#fa8b2f"}

    -   [**Inversion Sampling**]{style="color:#fa8b2f"}

    -   [**Rejection Sampling**]{style="color:#fa8b2f"}

    -   [**Importance Sampling**]{style="color:#fa8b2f"}

    -   [**Markov Chain Monte Carlo**]{style="color:#fa8b2f"}

    -   [**Variational Bayes**]{style="color:#fa8b2f"}

-   ***Still an open area of research!***

    -   [28 pages](https://link.springer.com/article/10.1007/s11222-015-9574-5), back in 2015

## Inversion Sampling

::: callout-important
## Theorem: Probability Integral Transform

Given a random variable $X \sim F_X$, we have that $U := F_X(X) \sim \mathrm{Unif}[0, 1]$
:::

-   Proof: found in PSTAT 120B (relatively simple using CDF method.)

-   Leads to following sampling scheme (often called [**Inversion Sampling**]{style="color:#fa8b2f"}):

    1)  Generate $U_1, \cdots, U_n \iid \mathrm{Unif}[0, 1]$

    2)  Apply quantile function of posterior to $U_1, \cdots, U_n$ to generate a sample $\theta_1, \cdots, \theta_n$ which will follow the posterior distribution.

## Inversion Sampling: Example

-   Example: use inversion sampling to generate a sample from the $\mathrm{Exp}(\beta)$ distribution.

-   CDF of $\mathrm{Exp}(\beta)$ distribution is $F_X(x) = 1 - e^{-x / \beta}$, so quantile function is $$ F_X^{-1}(u) = - \beta \ln(1 - u) $$

::: fragment
::: big-code
```{r}
#| echo: TRUE
quant_func <- Vectorize(function(u, beta) {
  return(-beta * log(1 - u))
})

set.seed(123)

U <- runif(500)
X <- quant_func(U, beta = 1)
```
:::
:::

## Inversion Sampling: Example

```{r dev = "png", dev.args=list(bg="transparent")}

data.frame(X) %>%
  ggplot(aes(x = X)) + 
  geom_histogram(aes(y = ..density..),
                 bins = 13,
                 col = "white",
                 fill = "#a4caebA0") +
  stat_function(fun = dexp,
                col = "#fa8b2f",
                linewidth = 1) +
  theme_minimal(base_size = 14) +
  xlab("x") + ylab("y") +
  theme(
    axis.text = element_text(colour = "white"),
    axis.title = element_text(colour = "white", size = 24),
    title = element_text(color = "white", size = 28),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.text = element_text(colour = "white",
                               size = 18),
    legend.title = element_text(size = 24)
  )

```

## Grid Approximation {style="font-size:32px"}

-   **Goal:** produce an *independent* sample of size $N$ $\{\theta^{(1)} , \cdots, \theta^{(N)}\}$ from a discretized approximation of posterior $p(\theta \mid x)$

-   Four main steps:

    1)  Specify discrete grid of possible $\theta$ values

    2)  Evaluate prior $\pi(\theta)$ and likelihood $p(y \mid \theta)$ at each point in grid

    3)  Multiply $\pi(\theta)$ and $p(y \mid \theta)$ at each point $\theta$ in the grid of possible values, then divide by the sum of the products (i.e. *normalize*)

    4)  Take a discrete unfiorm sample from the possible $\theta$ values, *with replacement*, with weights proportional to the values you computed in step (3)

## Example (due to Johnson, Ott, and Doğucu)

::: callout-note
## **Setup**

\begin{align*}
  (X \mid \theta)    & \sim \mathrm{Bin}(10, \pi)    \\
  \theta             & \sim \mathrm{Beta}(2, 2)
\end{align*} Observe $Y = 9$ (e.g. toss coin 10 times, and observe 9 heads). Goal: sample from posterior $p(\theta \mid 9)$.
:::

::: fragment
**Step 1:**

::: big-code
```{r}
#| echo: True
N <- 6
theta_grid <- seq(0, 1, length = N)
```
:::
:::

------------------------------------------------------------------------

::: fragment
**Step 2:**

::: big-code
```{r}
#| echo: True
discretized_prior <- dbeta(theta_grid, 2, 2)
discretized_likelihood <- dbinom(9, 10, theta_grid)
```
:::
:::

\

::: fragment
**Step 3:**

::: big-code
```{r}
#| echo: True

unnormalized_post <- discretized_prior *  discretized_likelihood

post <- unnormalized_post / sum(unnormalized_post)
round(post, 2)
```
:::
:::

------------------------------------------------------------------------

::: fragment
**Step 4:**

::: big-code
```{r}
#| echo: True
set.seed(123)
post_sample <- sample(theta_grid, 
                      size = 10000,
                      prob = post,
                      replace = T)
```
:::
:::

::: fragment
```{r dev = "png", dev.args=list(bg="transparent")}
data.frame(post_sample) %>%
  ggplot(aes(x = post_sample)) +
  geom_histogram(aes(y = ..density..),
                 bins = 13,
                 fill = "#a4caebA0",
                 col = "white") +
  stat_function(fun = dbeta,
                args = list(11, 3),
                col = "#fa8b2f",
                linewidth = 1.5) +
  theme_minimal(base_size = 12) +
  theme(
    axis.text = element_text(colour = "white"),
    axis.title = element_text(colour = "white", size = 24),
    title = element_text(color = "white", size = 28),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.text = element_text(colour = "white",
                               size = 18),
    legend.title = element_text(size = 24)
  ) +
  xlim(c(0, 1))
```
:::

------------------------------------------------------------------------

::: fragment
::: big-code
```{r}
#| echo: True
# Step 1
N <- 100
theta_grid <- seq(0, 1, length = N)

# Step 2
discretized_prior <- dbeta(theta_grid, 2, 2)
discretized_likelihood <- dbinom(9, 10, theta_grid)

# Step 3
unnormalized_post <- discretized_prior * discretized_likelihood

post <- unnormalized_post / sum(unnormalized_post)

# Step 4
set.seed(123)
post_sample <- sample(theta_grid, 
                      size = 10000,
                      prob = post,
                      replace = T)
```
:::
:::

------------------------------------------------------------------------

::: fragment
```{r dev = "png", dev.args=list(bg="transparent")}
data.frame(post_sample) %>%
  ggplot(aes(x = post_sample)) +
  geom_histogram(aes(y = ..density..),
                 bins = 13,
                 fill = "#a4caebA0",
                 col = "white") +
  stat_function(fun = dbeta,
                args = list(11, 3),
                col = "#fa8b2f",
                linewidth = 1.5) +
  theme_minimal(base_size = 12) +
  theme(
    axis.text = element_text(colour = "white"),
    axis.title = element_text(colour = "white", size = 24),
    title = element_text(color = "white", size = 28),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.text = element_text(colour = "white",
                               size = 18),
    legend.title = element_text(size = 24)
  ) +
  xlim(c(0, 1))
```
:::

## Pros and Cons

-   Not too difficult to code!

    -   Results are also pretty good, most of the time

-   **But**, can get computationally infeasible pretty quickly.

-   Especially true for models with not just one but *many* parameters

## Markov Chain Monte Carlo

-   One popular technique: [**Markov Chain Monte Carlo**]{style="color:#fa8b2f"}

-   General idea: forgo i.i.d.-ness of sample, opting instead for correlated samples that *converge* to the true posterior.

-   Specifically, produces a [**Markov Chain**]{style="color:#fa8b2f"} $\{\theta^{(1)} , \cdots, \theta^{(N)}\}$ whose limiting distribution is the posterior.

-   [**Markov Property**]{style="color:#fa8b2f"}: $\displaystyle p\left( \theta^{(i + 1)} \mid \theta^{(1)} , \cdots, \theta^{(i)} \right) = p\left( \theta^{(i + 1)} \mid \theta^{(i)}, y \right)$

-   Key point: none of the $\theta^{(i)}$'s are sampled directly from the posterior

## MCMC

-   I'll skip much of the details (as they involve material from PSTAT 160A).

-   Instead, we'll use `rstan`, an `R` package that allows us to use the programming language `Stan` (see [this](https://mc-stan.org/) link for more details on Stan)

-   Two main steps:

    1)  Define the Bayesian model structure
    2)  Simulate the posterior

## Step 1: Define Model Structure

-   Three aspects:

    -   `data`: what is the type of data that gets observed (integers? real numbers? vectors?)

    -   `parameters`: what are the parameters? What are their types (integers? real numbers? vectors?)

    -   `model`: what are the prior and likelihood?

-   Let's re-do our Beta-Binomial example, this time in `rstan`.

## Step 1: Define Model Structure

::: fragment
::: big-code
```{r}
#| echo: True
library(rstan)

beta_binom_model <- "
  data {
    int<lower = 0, upper = 10> Y;
  }
  parameters {
    real<lower = 0, upper = 1> theta;
  }
  model {
    Y ~ binomial(10, theta);
    theta ~ beta(2, 2);
  }
"
```
:::
:::

## Step 2: Simulate Posterior

-   Next, we simulate the posterior using the function `stan()`. (This might be quite slow for certain problems!)

-   Two main types of arguments:

    -   **Model Information**:

        -   `model_code` = our model specification (from Step 1)
        -   `data` = the observed data (in this case, \`Y = 9)

    -   **Markov Chain Information**:

        -   `chains`: how many parallel Markov chains should be run?
        -   `iter`: how many iterations in each chain (i.e. length of each chain)
        -   `seed`: setting the seed

------------------------------------------------------------------------

::: fragment
::: big-code
```{r}
#| echo: True
library(rstan)

beta_binom_sim <- stan(
  model_code = beta_binom_model,
  data = list(Y = 9),
  chains = 4,
  iter = 5000 * 2,
  seed = 123
)
```
:::
:::

------------------------------------------------------------------------

::: fragment
::: big-code
```{r}
#| echo: True
class(beta_binom_sim)
```
:::
:::

\

::: fragment
::: big-code
```{r}
#| echo: True
as.array(beta_binom_sim, pars = "theta") %>% head()
```
:::
:::

## Traceplot

::: fragment
::: big-code
```{r dev = "png", dev.args=list(bg="transparent")}
#| echo: False
library(bayesplot)
mcmc_trace(beta_binom_sim,
           pars = "theta",
           size = 0.5) +
  scale_colour_manual(values=c("red","blue","yellow","purple")) +
  theme(
    axis.text = element_text(colour = "white"),
    axis.title = element_text(colour = "white", size = 24),
    title = element_text(color = "white", size = 28),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.text = element_text(colour = "white",
                               size = 18),
    legend.title = element_text(size = 24)
  )
```
:::
:::

## Posterior Histogram

```{r dev = "png", dev.args=list(bg="transparent")}
mcmc_hist(beta_binom_sim, pars = "theta") +
  yaxis_text(TRUE) +
  ylab("count") +
  theme(
    axis.text = element_text(colour = "white"),
    axis.title = element_text(colour = "white", size = 24),
    title = element_text(color = "white", size = 28),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    legend.text = element_text(colour = "white",
                               size = 18),
    legend.title = element_text(size = 24)
  )
```

## Burn-In

-   In the context of MCMC, you'll often hear the word [**burnin**]{style="color:#fa8b2f"} used.

-   This refers to the practice of throwing out the first portion of the Markov chain values.

-   The rationale is as follows: our Markov chains only *converge* to the true posterior. In many cases, the chain doesn't quite get to the right posterior until much later in the simulation. Hence, while the chain is still learning the behavior of the posterior, it makes sense to throw out the initial values.

## Diagnostics

-   A crucial part of statistics is not only model-building, but also *diagnostics*.

-   A "good" Markov chain has traceplots that resemble white noise, with no noticeable trend or phenomena.

-   On the other hand, "bad" Markov chains may display trend (which is indicative of a chain that hasn't mixed well), or might get stuck at certain values of the parameter space.

## Example (due to Johnson, Ott, and Doğucu)

![](bad-trace-1.png)

## Possible Fixes

1)  Check the model, and reassess its fit

2)  Run the chain for more iterations

\

-   Another diagnostic tool: check whether the multiple chains have mixed well. (Remember that we generated 4!)

# Selfish Diversion

## Final Thoughts

-   Consider a statistical modeling problem: $$ y_i = f(x_i) + \varepsilon_i $$ with $\varepsilon_i \stackrel{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2)$

-   Much literature devoted to estimation of $f(\cdot)$.

-   Idea: borrow from Bayesian framework and *assign a prior to* $f(\cdot)$!

-   Lot's of choices of (albeit weird) priors: [**Dirichlet Processes**]{style="color:#fa8b2f"} and [**Gaussian Processes**]{style="color:#fa8b2f"}.

-   I'm actually working with the latter in my ongoing research, but maybe that's a tale for another time...

# Selected Proofs

## Theorem 1 {style="font-size:28px"}

> Let $A$ be an event with probability of occurrence $\Prob(A)$. Let $Y_n$ be defined as the proportion of times the event $A$ occurs in $n$ repetitions of the underlying experiment: then $Y_n$ converges to $\Prob(A)$ in probability: $$ Y_n \stackrel{p}{\longrightarrow} \Prob(A) $$

-   Let $X_i = \1_{\{\text{$A$ occurs on $i$th trial}\}} \sim \mathrm{Bern}(\Prob(A))$

-   Then, $Y_n = n^{-1} \sum_{i=1}^{n} X_i =: \overline{X}_n$.

-   By the Weak Law of Large Numbers (which we can invoke since $\E[X_i] = \Prob(A) < \infty$ and $\Var(X_i) = \Prob(A) \Prob(A^{\complement}) < \infty$), we have that $$ Y_n = \overline{X}_n \stackrel{p}{\longrightarrow} \E[X_i] = \Prob(A) $$

## Probability Integral Transform {style="font-size:28px"}

> Given a continuous random variable $X \sim F_X$, we have that $U := F_X(X) \sim \mathrm{Unif}[0, 1]$

-   First note: $F_X(\cdot)$ is monotone increasing, and hence invertible.

    -   Inverse (quantile function) is also monotone increasing.

-   By CDF Method, \begin{align*}
      F_U(u)    & := \Prob(U \leq u)    \\
            & = \Prob(F_X(X) \leq u) = \Prob(X \leq F_X^{-1}(u))    \\
            & = F_X[F_X^{-1}(u)] = u
    \end{align*} which is the CDF of the $\mathrm{Unif}[0, 1]$ distribution.

    -   Direction of inequality does not change, due to monotone increasing nature of $F_X^{-1}(\cdot)$.
